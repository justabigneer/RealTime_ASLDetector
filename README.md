Real-Time American Sign Language (ASL) Recognition System
AI & DSML Project

A deep learningâ€“based real-time American Sign Language (ASL) recognition system developed as part of the Artificial Intelligence (AI) and Data Science & Machine Learning (DSML) coursework at Pokhara University.

This project integrates:

 YOLOv8 for hand detection (identification/localization)

 Convolutional Neural Network (CNN) for gesture classification

FastAPI for backend inference

Streamlit for web-based deployment

The system enables real-time recognition of ASL alphabet gestures using a webcam.

ğŸ“Œ Project Motivation

Communication barriers between hearing-impaired individuals and non-signers create accessibility challenges. This project aims to provide a real-time automated solution that detects and recognizes static ASL alphabet gestures using computer vision and deep learning techniques.

The project demonstrates practical application of:

Deep Learning

Computer Vision

Model Deployment

API Integration

Full-stack ML system design

 System Architecture
Webcam Input
      â†“
YOLOv8 Model (Hand Detection)
      â†“
Hand Region Cropping
      â†“
CNN Model (Gesture Classification)
      â†“
FastAPI Backend
      â†“
Streamlit Web Interface
      â†“
Predicted ASL Character

 Model Development
1ï¸âƒ£ CNN â€“ Gesture Classification

Input Shape: 64 Ã— 64 Ã— 3

Total Output Classes: 29

Aâ€“Z

del

space

nothing

Activation Functions:

ReLU (hidden layers)

Softmax (output layer)

Optimizer: Adam

Loss Function: Categorical Cross-Entropy

Data Normalization: Pixel scaling (0â€“1)

Validation Strategy: Stratified K-Fold Cross Validation

2ï¸âƒ£ YOLOv8 â€“ Hand Detection

Custom-trained YOLOv8 model

Used for real-time hand localization

Cropped bounding box passed to CNN

Confidence threshold configurable

 Dataset Description

Dataset: ASL Alphabet Dataset

Classes: 29

Image Type: RGB

Preprocessing Steps:

Image resizing to 64Ã—64

Normalization

Data augmentation (if applied)

ğŸ“ˆ Model Performance
Metric	Value (Replace with yours)
Accuracy	95%
Precision	94%
Recall	93%
F1-Score	94%
ROC-AUC	0.97

Evaluation tools used:

Confusion Matrix

ROC Curve

Accuracy/Loss Graphs

 Deployment Architecture

This system is deployed as a web-based application using a two-layer architecture:

ğŸ”¹ FastAPI (Backend)

Loads trained CNN and YOLO models

Handles inference requests

Returns JSON prediction responses

Run backend:

uvicorn api.main:app --reload

ğŸ”¹ Streamlit (Frontend)

User-friendly web interface

Webcam integration

Displays real-time predictions

Run frontend:

streamlit run app/streamlit_app.py

 Project Structure
ASL-Recognition/
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ cnn_model.keras
â”‚   â””â”€â”€ best.pt
â”‚
â”œâ”€â”€ training/
â”‚   â”œâ”€â”€ cnn_training.py
â”‚   â””â”€â”€ yolo_training.py
â”‚
â”œâ”€â”€ app.ph
â”‚â”€â”€ stream_app.py
â”‚
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

 Technologies Used

Python

TensorFlow / Keras

Ultralytics YOLOv8

OpenCV

FastAPI

Streamlit

NumPy

## Learning Outcomes

Through this AI & DSML project, we gained experience in:

Designing deep learning architectures

Model training and evaluation

Object detection using YOLO

API-based ML deployment

Full-stack ML application development

Performance evaluation using ROC and confusion matrix

ğŸ‘¥ Project Team

This project was developed by a team of three students as part of the AI & DSML coursework at Pokhara University.

Aditi kc

Anukriti Thapa

Rashi Bista
